apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    azuredisk-csi: "true"
    cloud-provider: ${CLOUD_PROVIDER_AZURE_LABEL:=azure}
    cni: calico
    storageclass: "true"
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 192.168.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureCluster
    name: ${CLUSTER_NAME}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  additionalTags:
    buildProvenance: ${BUILD_PROVENANCE}
    creationTimestamp: ${TIMESTAMP}
    jobName: ${JOB_NAME}
  identityRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureClusterIdentity
    name: ${CLUSTER_IDENTITY_NAME}
  location: ${AZURE_LOCATION}
  networkSpec:
    subnets:
    - name: control-plane-subnet
      role: control-plane
    - name: node-subnet
      role: node
    vnet:
      name: ${AZURE_VNET_NAME:=${CLUSTER_NAME}-vnet}
  resourceGroup: ${AZURE_RESOURCE_GROUP:=${CLUSTER_NAME}}
  subscriptionID: ${AZURE_SUBSCRIPTION_ID}
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  annotations:
    controlplane.cluster.x-k8s.io/skip-kube-proxy: "true"
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        extraArgs: {}
        timeoutForControlPlane: 20m
      controllerManager:
        extraArgs:
          allocate-node-cidrs: "false"
          cloud-provider: external
          cluster-name: ${CLUSTER_NAME}
          v: "4"
      etcd:
        local:
          dataDir: /var/lib/etcddisk/etcd
          extraArgs:
            quota-backend-bytes: "8589934592"
      kubernetesVersion: ci/${CI_VERSION}
      scheduler:
        extraArgs:
          authorization-always-allow-paths: /healthz,/readyz,/livez,/metrics
          bind-address: 0.0.0.0
    diskSetup:
      filesystems:
      - device: /dev/disk/azure/scsi1/lun0
        extraOpts:
        - -E
        - lazy_itable_init=1,lazy_journal_init=1
        filesystem: ext4
        label: etcd_disk
      - device: ephemeral0.1
        filesystem: ext4
        label: ephemeral0
        replaceFS: ntfs
      partitions:
      - device: /dev/disk/azure/scsi1/lun0
        layout: true
        overwrite: false
        tableType: gpt
    files:
    - content: |
        #!/bin/bash

        set -o nounset
        set -o pipefail
        set -o errexit

        systemctl stop kubelet

        declare -a BINARIES=("kubeadm" "kubectl" "kubelet")

        # Run the az login command with managed identity
        if az login --identity > /dev/null 2>&1; then
          echo "Logged in Azure with managed identity"
          for BINARY in "$${BINARIES[@]}"; do
            echo "* installing package: $${BINARY} ${KUBE_GIT_VERSION}"
            az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${KUBE_GIT_VERSION}/bin/linux/amd64/$${BINARY}" -f "/usr/bin/$${BINARY}" --auth-mode login
          done
        else
          echo "Using curl to download the binaries"
          for BINARY in "$${BINARIES[@]}"; do
            echo "* installing package: $${BINARY} ${KUBE_GIT_VERSION}"
            curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${KUBE_GIT_VERSION}/bin/linux/amd64/$${BINARY}" --output "/usr/bin/$${BINARY}"
          done
        fi
        systemctl restart kubelet

        # prepull images from gcr.io/k8s-staging-ci-images and retag it to
        # registry.k8s.io so kubeadm can fetch correct images no matter what
        declare -a IMAGES=("kube-apiserver" "kube-controller-manager" "kube-proxy" "kube-scheduler")
        [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""
        IMAGE_REGISTRY_PREFIX=registry.k8s.io
        for IMAGE in "$${IMAGES[@]}"; do
          $${SUDO} ctr -n k8s.io images tag $$IMAGE_REGISTRY_PREFIX/$$IMAGE-amd64:"${CI_VERSION//+/_}" $$IMAGE_REGISTRY_PREFIX/$$IMAGE:"${CI_VERSION//+/_}"
          $${SUDO} ctr -n k8s.io images tag $$IMAGE_REGISTRY_PREFIX/$$IMAGE-amd64:"${CI_VERSION//+/_}" gcr.io/k8s-staging-ci-images/$$IMAGE:"${CI_VERSION//+/_}"
        done

        echo "kubeadm version: $(kubeadm version -o=short)"
        echo "kubectl version: $(kubectl version --client=true)"
        echo "kubelet version: $(kubelet --version)"
      owner: root:root
      path: /tmp/replace-k8s-binaries.sh
      permissions: "0744"
    - content: |
        #!/bin/bash

        set -o nounset
        set -o pipefail
        set -o errexit

        curl -L --retry 10 --retry-delay 5 https://github.com/mikefarah/yq/releases/download/v4.6.1/yq_linux_amd64.tar.gz --output /tmp/yq_linux_amd64.tar.gz
        tar -xzvf /tmp/yq_linux_amd64.tar.gz -C /tmp && mv /tmp/yq_linux_amd64 /usr/bin/yq
        rm /tmp/yq_linux_amd64.tar.gz

        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl -n kube-system set image daemonset/kube-proxy kube-proxy="${REGISTRY}/kube-proxy:${KUBE_IMAGE_TAG}"
        systemctl stop kubelet
        yq e '.spec.containers[0].image = "${REGISTRY}/kube-apiserver:${KUBE_IMAGE_TAG}"' -i /etc/kubernetes/manifests/kube-apiserver.yaml
        yq e '.spec.containers[0].image = "${REGISTRY}/kube-controller-manager:${KUBE_IMAGE_TAG}"' -i /etc/kubernetes/manifests/kube-controller-manager.yaml
        yq e '.spec.containers[0].image = "${REGISTRY}/kube-scheduler:${KUBE_IMAGE_TAG}"' -i /etc/kubernetes/manifests/kube-scheduler.yaml
        systemctl restart kubelet
      owner: root:root
      path: /tmp/replace-k8s-components.sh
      permissions: "0744"
    - contentFrom:
        secret:
          key: control-plane-azure.json
          name: ${CLUSTER_NAME}-control-plane-azure-json
      owner: root:root
      path: /etc/kubernetes/azure.json
      permissions: "0644"
    - content: |
        #!/bin/bash

        set -o nounset
        set -o pipefail
        set -o errexit
        [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""

        # Run the az login command with managed identity
        if az login --identity > /dev/null 2>&1; then
          echo "Logged in Azure with managed identity"
          echo "Use OOT credential provider"
          mkdir -p /var/lib/kubelet/credential-provider
          az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider" -f /var/lib/kubelet/credential-provider/acr-credential-provider --auth-mode login
          chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
          az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml" -f /var/lib/kubelet/credential-provider-config.yaml --auth-mode login
          chmod 644 /var/lib/kubelet/credential-provider-config.yaml
        else
          echo "Using curl to download the OOT credential provider"
          mkdir -p /var/lib/kubelet/credential-provider
          curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider/acr-credential-provider "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider"
          chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
          curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider-config.yaml "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml"
          chmod 644 /var/lib/kubelet/credential-provider-config.yaml
        fi
      owner: root:root
      path: /tmp/oot-cred-provider.sh
      permissions: "0744"
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external
          image-credential-provider-bin-dir: /var/lib/kubelet/credential-provider
          image-credential-provider-config: /var/lib/kubelet/credential-provider-config.yaml
        name: '{{ ds.meta_data["local_hostname"] }}'
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external
          image-credential-provider-bin-dir: /var/lib/kubelet/credential-provider
          image-credential-provider-config: /var/lib/kubelet/credential-provider-config.yaml
        name: '{{ ds.meta_data["local_hostname"] }}'
    mounts:
    - - LABEL=etcd_disk
      - /var/lib/etcddisk
    postKubeadmCommands:
    - bash -c /tmp/replace-k8s-components.sh
    preKubeadmCommands:
    - bash -c /tmp/replace-k8s-binaries.sh
    - bash -c /tmp/oot-cred-provider.sh
    verbosity: 5
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: AzureMachineTemplate
      name: ${CLUSTER_NAME}-control-plane
  replicas: ${CONTROL_PLANE_MACHINE_COUNT:=1}
  version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  template:
    spec:
      additionalTags:
        monitoring: load
      dataDisks:
      - diskSizeGB: 256
        lun: 0
        nameSuffix: etcddisk
      identity: UserAssigned
      image:
        marketplace:
          offer: capi
          publisher: cncf-upstream
          sku: ubuntu-2204-gen1
          version: latest
      osDisk:
        diskSizeGB: 128
        osType: Linux
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      userAssignedIdentities:
      - providerID: /subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${CI_RG:=capz-ci}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/${USER_IDENTITY:=cloud-provider-user-identity}
      vmSize: ${AZURE_CONTROL_PLANE_MACHINE_TYPE}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachinePool
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_MACHINE_COUNT:=2}
  template:
    metadata:
      labels:
        nodepool: pool1
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfig
          name: ${CLUSTER_NAME}-mp-0
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachinePool
        name: ${CLUSTER_NAME}-mp-0
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachinePool
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  additionalTags:
    monitoring: load
  location: ${AZURE_LOCATION}
  strategy:
    rollingUpdate:
      deletePolicy: Oldest
      maxSurge: 25%
      maxUnavailable: 1
    type: RollingUpdate
  template:
    image:
      marketplace:
        offer: capi
        publisher: cncf-upstream
        sku: ubuntu-2204-gen1
        version: latest
    osDisk:
      diskSizeGB: 30
      managedDisk:
        storageAccountType: Premium_LRS
      osType: Linux
    sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
    vmExtensions:
    - name: CustomScript
      protectedSettings:
        commandToExecute: |
          #!/bin/sh
          echo "This script is a no-op used for extension testing purposes ..."
          touch test_file
      publisher: Microsoft.Azure.Extensions
      version: "2.1"
    vmSize: ${AZURE_NODE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfig
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  files:
  - content: |
      #!/bin/bash

      set -o nounset
      set -o pipefail
      set -o errexit
      [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""

      # Run the az login command with managed identity
      if az login --identity > /dev/null 2>&1; then
        echo "Logged in Azure with managed identity"
        echo "Use OOT credential provider"
        mkdir -p /var/lib/kubelet/credential-provider
        az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider" -f /var/lib/kubelet/credential-provider/acr-credential-provider --auth-mode login
        chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
        az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml" -f /var/lib/kubelet/credential-provider-config.yaml --auth-mode login
        chmod 644 /var/lib/kubelet/credential-provider-config.yaml
      else
        echo "Using curl to download the OOT credential provider"
        mkdir -p /var/lib/kubelet/credential-provider
        curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider/acr-credential-provider "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider"
        chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
        curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider-config.yaml "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml"
        chmod 644 /var/lib/kubelet/credential-provider-config.yaml
      fi
    owner: root:root
    path: /tmp/oot-cred-provider.sh
    permissions: "0744"
  - content: |
      #!/bin/bash

      set -o nounset
      set -o pipefail
      set -o errexit

      systemctl stop kubelet
      declare -a BINARIES=("kubeadm" "kubectl" "kubelet")
      for BINARY in "$${BINARIES[@]}"; do
        echo "* installing package: $${BINARY} ${KUBE_GIT_VERSION}"
        curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${KUBE_GIT_VERSION}/bin/linux/amd64/$${BINARY}" --output "/usr/bin/$${BINARY}"
      done
      systemctl restart kubelet

      echo "kubeadm version: $(kubeadm version -o=short)"
      echo "kubectl version: $(kubectl version --client=true)"
      echo "kubelet version: $(kubelet --version)"
    owner: root:root
    path: /tmp/replace-k8s-binaries.sh
    permissions: "0744"
  - contentFrom:
      secret:
        key: control-plane-azure.json
        name: ${CLUSTER_NAME}-control-plane-azure-json
    owner: root:root
    path: /etc/kubernetes/azure.json
    permissions: "0644"
  joinConfiguration:
    nodeRegistration:
      kubeletExtraArgs:
        cloud-provider: external
        image-credential-provider-bin-dir: /var/lib/kubelet/credential-provider
        image-credential-provider-config: /var/lib/kubelet/credential-provider-config.yaml
      name: '{{ ds.meta_data["local_hostname"] }}'
  preKubeadmCommands:
  - bash -c /tmp/oot-cred-provider.sh
  - bash -c /tmp/replace-k8s-binaries.sh
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureClusterIdentity
metadata:
  labels:
    clusterctl.cluster.x-k8s.io/move-hierarchy: "true"
  name: ${CLUSTER_IDENTITY_NAME}
  namespace: default
spec:
  allowedNamespaces: {}
  clientID: ${AZURE_CLIENT_ID_USER_ASSIGNED_IDENTITY}
  tenantID: ${AZURE_TENANT_ID}
  type: ${CLUSTER_IDENTITY_TYPE:=WorkloadIdentity}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  maxUnhealthy: 100%
  selector:
    matchLabels:
      cluster.x-k8s.io/control-plane: ""
  unhealthyConditions:
  - status: Unknown
    timeout: 300s
    type: Ready
  - status: "False"
    timeout: 300s
    type: Ready
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: ${CLUSTER_NAME}-mhc-0
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  maxUnhealthy: 100%
  selector:
    matchLabels:
      nodepool: pool1
  unhealthyConditions:
  - status: "True"
    timeout: 30s
    type: E2ENodeUnhealthy
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: calico
  namespace: default
spec:
  chartName: tigera-operator
  clusterSelector:
    matchLabels:
      cni: calico
  namespace: tigera-operator
  releaseName: projectcalico
  repoURL: https://docs.tigera.io/calico/charts
  valuesTemplate: |
    installation:
      cni:
        type: Calico
        ipam:
          type: Calico
      calicoNetwork:
        bgp: Disabled
        windowsDataplane: HNS
        mtu: 1350
        ipPools:{{range $i, $cidr := .Cluster.spec.clusterNetwork.pods.cidrBlocks }}
        - cidr: {{ $cidr }}
          encapsulation: VXLAN{{end}}
      typhaDeployment:
        spec:
          template:
            spec:
              # By default, typha tolerates all NoSchedule taints. This breaks
              # scale-ins when it continuously gets scheduled onto an
              # out-of-date Node that is being deleted. Tolerate only the
              # NoSchedule taints that are expected.
              tolerations:
                - effect: NoExecute
                  operator: Exists
                - effect: NoSchedule
                  key: node-role.kubernetes.io/control-plane
                  operator: Exists
                - effect: NoSchedule
                  key: node.kubernetes.io/not-ready
                  operator: Exists
              affinity:
                nodeAffinity:
                  preferredDuringSchedulingIgnoredDuringExecution:
                  - weight: 50
                    preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
      registry: capzcicommunity.azurecr.io
      serviceCIDRs:
        - 10.96.0.0/12 # must match cluster service CIDR (this is the default)
    # Image and registry configuration for the tigera/operator pod
    tigeraOperator:
      image: tigera/operator
      registry: capzcicommunity.azurecr.io
    calicoctl:
      image: capzcicommunity.azurecr.io/calico/ctl
    # when kubernetesServiceEndpoint (required for windows) is added
    # DNS configuration is needed to look up the api server name properly
    # https://github.com/projectcalico/calico/issues/9536
    dnsConfig:
      nameservers:
        - 127.0.0.53
      options:
        - name: edns0
        - name: trust-ad
    kubernetesServiceEndpoint:
      host: "{{ .Cluster.spec.controlPlaneEndpoint.host }}"
      port: "{{ .Cluster.spec.controlPlaneEndpoint.port }}"
    # By default, tigera tolerates all NoSchedule taints. This breaks upgrades
    # when it continuously gets scheduled onto an out-of-date Node that is being
    # deleted. Tolerate only the NoSchedule taints that are expected.
    tolerations:
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
        operator: Exists
      - effect: NoSchedule
        key: node.kubernetes.io/not-ready
        operator: Exists
  version: ${CALICO_VERSION}
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: azuredisk-csi-driver-chart
  namespace: default
spec:
  chartName: azuredisk-csi-driver
  clusterSelector:
    matchLabels:
      azuredisk-csi: "true"
  namespace: kube-system
  releaseName: azuredisk-csi-driver-oot
  repoURL: https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/charts
  valuesTemplate: |-
    controller:
      replicas: 1
      runOnControlPlane: true
    windows:
      useHostProcessContainers: {{ hasKey .Cluster.metadata.labels "cni-windows" }}
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: cloud-provider-azure-chart
  namespace: default
spec:
  chartName: cloud-provider-azure
  clusterSelector:
    matchLabels:
      cloud-provider: azure
  releaseName: cloud-provider-azure-oot
  repoURL: https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo
  valuesTemplate: |
    infra:
      clusterName: {{ .Cluster.metadata.name }}
    cloudControllerManager:
      clusterCIDR: {{ .Cluster.spec.clusterNetwork.pods.cidrBlocks | join "," }}
      logVerbosity: 4
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: cloud-provider-azure-chart-ci
  namespace: default
spec:
  chartName: cloud-provider-azure
  clusterSelector:
    matchLabels:
      cloud-provider: azure-ci
  releaseName: cloud-provider-azure-oot
  repoURL: https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo
  valuesTemplate: |
    infra:
      clusterName: {{ .Cluster.metadata.name }}
    cloudControllerManager:
      cloudConfig: ${CLOUD_CONFIG:-"/etc/kubernetes/azure.json"}
      cloudConfigSecretName: ${CONFIG_SECRET_NAME:-""}
      clusterCIDR: {{ .Cluster.spec.clusterNetwork.pods.cidrBlocks | join "," }}
      imageName: "${CCM_IMAGE_NAME:-""}"
      imageRepository: "${IMAGE_REGISTRY:-""}"
      imageTag: "${IMAGE_TAG_CCM:-""}"
      logVerbosity: ${CCM_LOG_VERBOSITY:-4}
      replicas: ${CCM_COUNT:-1}
      enableDynamicReloading: ${ENABLE_DYNAMIC_RELOADING:-false}
    cloudNodeManager:
      imageName: "${CNM_IMAGE_NAME:-""}"
      imageRepository: "${IMAGE_REGISTRY:-""}"
      imageTag: "${IMAGE_TAG_CNM:-""}"
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: ${CLUSTER_NAME}-monitoring
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${MONITORING_MACHINE_COUNT:=0}
  selector: {}
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-monitoring
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachineTemplate
        name: ${CLUSTER_NAME}-monitoring
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-monitoring
  namespace: default
spec:
  template:
    spec:
      additionalTags:
        monitoring: load
      identity: UserAssigned
      image:
        marketplace:
          offer: capi
          publisher: cncf-upstream
          sku: ubuntu-2204-gen1
          version: latest
      osDisk:
        diskSizeGB: 128
        osType: Linux
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      userAssignedIdentities:
      - providerID: /subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${CI_RG}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/${USER_IDENTITY}
      vmSize: ${AZURE_CONTROL_PLANE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${CLUSTER_NAME}-monitoring
  namespace: default
spec:
  template:
    spec:
      files:
      - contentFrom:
          secret:
            key: worker-node-azure.json
            name: ${CLUSTER_NAME}-monitoring-azure-json
        owner: root:root
        path: /etc/kubernetes/azure.json
        permissions: "0644"
      - content: |
          #!/bin/bash

          set -o nounset
          set -o pipefail
          set -o errexit
          [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""

          # Run the az login command with managed identity
          if az login --identity > /dev/null 2>&1; then
            echo "Logged in Azure with managed identity"
            echo "Use OOT credential provider"
            mkdir -p /var/lib/kubelet/credential-provider
            az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider" -f /var/lib/kubelet/credential-provider/acr-credential-provider --auth-mode login
            chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
            az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml" -f /var/lib/kubelet/credential-provider-config.yaml --auth-mode login
            chmod 644 /var/lib/kubelet/credential-provider-config.yaml
          else
            echo "Use OOT credential provider"
            mkdir -p /var/lib/kubelet/credential-provider
            curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider/acr-credential-provider "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/azure-acr-credential-provider"
            chmod 755 /var/lib/kubelet/credential-provider/acr-credential-provider
            curl --retry 10 --retry-delay 5 -w "response status code is %{http_code}" -Lo /var/lib/kubelet/credential-provider-config.yaml "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${IMAGE_TAG_ACR_CREDENTIAL_PROVIDER}/credential-provider-config.yaml"
            chmod 644 /var/lib/kubelet/credential-provider-config.yaml
          fi
        owner: root:root
        path: /tmp/oot-cred-provider.sh
        permissions: "0744"
      - content: |
          #!/bin/bash

          set -o nounset
          set -o pipefail
          set -o errexit

          systemctl stop kubelet
          declare -a BINARIES=("kubeadm" "kubectl" "kubelet")
          az login --identity
          for BINARY in "$${BINARIES[@]}"; do
            echo "* installing package: $${BINARY} ${KUBE_GIT_VERSION}"
            az storage blob download --blob-url "https://${AZURE_STORAGE_ACCOUNT}.blob.core.windows.net/${AZURE_BLOB_CONTAINER_NAME}/${KUBE_GIT_VERSION}/bin/linux/amd64/$${BINARY}" -f "/usr/bin/$${BINARY}" --auth-mode login
          done
          systemctl restart kubelet

          echo "kubeadm version: $(kubeadm version -o=short)"
          echo "kubectl version: $(kubectl version --client=true)"
          echo "kubelet version: $(kubelet --version)"
        owner: root:root
        path: /tmp/replace-k8s-binaries.sh
        permissions: "0744"
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            cloud-provider: external
            image-credential-provider-bin-dir: /var/lib/kubelet/credential-provider
            image-credential-provider-config: /var/lib/kubelet/credential-provider-config.yaml
            register-with-taints: monitoring:NoSchedule
          name: '{{ ds.meta_data["local_hostname"] }}'
      preKubeadmCommands:
      - bash -c /tmp/oot-cred-provider.sh
      - bash -c /tmp/replace-k8s-binaries.sh
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: ${CLUSTER_NAME}-storageclass
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      storageclass: "true"
  resources:
  - kind: ConfigMap
    name: ${CLUSTER_NAME}-storageclass
  strategy: ApplyOnce
---
apiVersion: v1
data:
  storageclass: |
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: default
      annotations:
        storageclass.beta.kubernetes.io/is-default-class: "true"
      labels:
        kubernetes.io/cluster-service: "true"
    provisioner: kubernetes.io/azure-disk
    parameters:
      kind: Managed
      storageaccounttype: Standard_LRS
      cachingmode: ReadOnly
    volumeBindingMode: WaitForFirstConsumer
    ---
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: managed-premium
      annotations:
      labels:
        kubernetes.io/cluster-service: "true"
    provisioner: kubernetes.io/azure-disk
    parameters:
      kind: Managed
      storageaccounttype: Premium_LRS
      cachingmode: ReadOnly
    volumeBindingMode: WaitForFirstConsumer
    ---
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: managed-standard
      annotations:
      labels:
        kubernetes.io/cluster-service: "true"
    provisioner: kubernetes.io/azure-disk
    parameters:
      kind: Managed
      storageaccounttype: Standard_LRS
      cachingmode: ReadOnly
    volumeBindingMode: WaitForFirstConsumer
kind: ConfigMap
metadata:
  annotations:
    note: generated
  labels:
    type: generated
  name: ${CLUSTER_NAME}-storageclass
  namespace: default
