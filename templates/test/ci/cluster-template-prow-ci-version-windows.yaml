apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    cni: ${CLUSTER_NAME}-flannel
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 10.244.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureCluster
    name: ${CLUSTER_NAME}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  additionalTags:
    buildProvenance: ${BUILD_PROVENANCE}
    creationTimestamp: ${TIMESTAMP}
    jobName: ${JOB_NAME}
  identityRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureClusterIdentity
    name: ${CLUSTER_IDENTITY_NAME}
  location: ${AZURE_LOCATION}
  networkSpec:
    subnets:
    - name: control-plane-subnet
      role: control-plane
    - name: node-subnet
      natGateway:
        name: node-natgateway
      role: node
    vnet:
      name: ${AZURE_VNET_NAME:=${CLUSTER_NAME}-vnet}
  resourceGroup: ${AZURE_RESOURCE_GROUP:=${CLUSTER_NAME}}
  subscriptionID: ${AZURE_SUBSCRIPTION_ID}
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        extraArgs:
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        extraVolumes:
        - hostPath: /etc/kubernetes/azure.json
          mountPath: /etc/kubernetes/azure.json
          name: cloud-config
          readOnly: true
        timeoutForControlPlane: 20m
      controllerManager:
        extraArgs:
          allocate-node-cidrs: "true"
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
          cluster-name: ${CLUSTER_NAME}
          configure-cloud-routes: "false"
          v: "4"
        extraVolumes:
        - hostPath: /etc/kubernetes/azure.json
          mountPath: /etc/kubernetes/azure.json
          name: cloud-config
          readOnly: true
      etcd:
        local:
          dataDir: /var/lib/etcddisk/etcd
          extraArgs:
            quota-backend-bytes: "8589934592"
      kubernetesVersion: ci/${CI_VERSION}
    diskSetup:
      filesystems:
      - device: /dev/disk/azure/scsi1/lun0
        extraOpts:
        - -E
        - lazy_itable_init=1,lazy_journal_init=1
        filesystem: ext4
        label: etcd_disk
      - device: ephemeral0.1
        filesystem: ext4
        label: ephemeral0
        replaceFS: ntfs
      partitions:
      - device: /dev/disk/azure/scsi1/lun0
        layout: true
        overwrite: false
        tableType: gpt
    files:
    - content: |
        network:
          version: 2
          ethernets:
            eth0:
              mtu: 1400
              match:
                macaddress: MACADDRESS
              set-name: eth0
      owner: root:root
      path: /etc/netplan/60-eth0.yaml
      permissions: "0644"
    - contentFrom:
        secret:
          key: control-plane-azure.json
          name: ${CLUSTER_NAME}-control-plane-azure-json
      owner: root:root
      path: /etc/kubernetes/azure.json
      permissions: "0644"
    - content: |
        #!/bin/bash

        set -o nounset
        set -o pipefail
        set -o errexit
        [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""

        # This test installs release packages or binaries that are a result of the CI and release builds.
        # It runs '... --version' commands to verify that the binaries are correctly installed
        # and finally uninstalls the packages.
        # For the release packages it tests all versions in the support skew.
        LINE_SEPARATOR="*************************************************"
        echo "$$LINE_SEPARATOR"
        CI_VERSION=${CI_VERSION}
        if [[ "$${CI_VERSION}" != "" ]]; then
          CI_DIR=/tmp/k8s-ci
          mkdir -p $$CI_DIR
          declare -a PACKAGES_TO_TEST=("kubectl" "kubelet" "kubeadm")
          declare -a CONTAINERS_TO_TEST=("kube-apiserver" "kube-controller-manager" "kube-proxy" "kube-scheduler")
          CONTAINER_EXT="tar"
          echo "* testing CI version $$CI_VERSION"
          # Check for semver
          if [[ "$${CI_VERSION}" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            CI_URL="https://storage.googleapis.com/k8s-release-dev/ci/$${CI_VERSION}/bin/linux/amd64"
            VERSION_WITHOUT_PREFIX="${CI_VERSION#v}"
            DEBIAN_FRONTEND=noninteractive apt-get install -y apt-transport-https curl
            curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
            echo 'deb https://apt.kubernetes.io/ kubernetes-xenial main' > /etc/apt/sources.list.d/kubernetes.list
            apt-get update
            # replace . with \.
            VERSION_REGEX="${VERSION_WITHOUT_PREFIX//./\\.}"
            PACKAGE_VERSION="$(apt-cache madison kubelet|grep $${VERSION_REGEX}- | head -n1 | cut -d '|' -f 2 | tr -d '[:space:]')"
            for CI_PACKAGE in "$${PACKAGES_TO_TEST[@]}"; do
              echo "* installing package: $$CI_PACKAGE $${PACKAGE_VERSION}"
              DEBIAN_FRONTEND=noninteractive apt-get install -y $$CI_PACKAGE=$$PACKAGE_VERSION
            done
          else
              CI_URL="https://storage.googleapis.com/k8s-release-dev/ci/$${CI_VERSION}/bin/linux/amd64"
            fi
            for CI_PACKAGE in "$${PACKAGES_TO_TEST[@]}"; do
              echo "* downloading binary: $$CI_URL/$$CI_PACKAGE"
              wget "$$CI_URL/$$CI_PACKAGE" -O "$$CI_DIR/$$CI_PACKAGE"
              chmod +x "$$CI_DIR/$$CI_PACKAGE"
              mv "$$CI_DIR/$$CI_PACKAGE" "/usr/bin/$$CI_PACKAGE"
            done
            systemctl restart kubelet
          fi
          for CI_CONTAINER in "$${CONTAINERS_TO_TEST[@]}"; do
            echo "* downloading package: $$CI_URL/$$CI_CONTAINER.$$CONTAINER_EXT"
            wget "$$CI_URL/$$CI_CONTAINER.$$CONTAINER_EXT" -O "$$CI_DIR/$$CI_CONTAINER.$$CONTAINER_EXT"
            $${SUDO} ctr -n k8s.io images import "$$CI_DIR/$$CI_CONTAINER.$$CONTAINER_EXT" || echo "* ignoring expected 'ctr images import' result"
            $${SUDO} ctr -n k8s.io images tag k8s.gcr.io/$$CI_CONTAINER-amd64:"$${CI_VERSION//+/_}" k8s.gcr.io/$$CI_CONTAINER:"$${CI_VERSION//+/_}"
            $${SUDO} ctr -n k8s.io images tag k8s.gcr.io/$$CI_CONTAINER-amd64:"$${CI_VERSION//+/_}" gcr.io/k8s-staging-ci-images/$$CI_CONTAINER:"$${CI_VERSION//+/_}"
          done
        fi
        echo "* checking binary versions"
        echo "ctr version: " $(ctr version)
        echo "kubeadm version: " $(kubeadm version -o=short)
        echo "kubectl version: " $(kubectl version --client=true --short=true)
        echo "kubelet version: " $(kubelet --version)
        echo "$$LINE_SEPARATOR"
      owner: root:root
      path: /tmp/kubeadm-bootstrap.sh
      permissions: "0744"
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          azure-container-registry-config: /etc/kubernetes/azure.json
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        name: '{{ ds.meta_data["local_hostname"] }}'
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          azure-container-registry-config: /etc/kubernetes/azure.json
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        name: '{{ ds.meta_data["local_hostname"] }}'
    mounts:
    - - LABEL=etcd_disk
      - /var/lib/etcddisk
    postKubeadmCommands:
    - mac=$(ip -o link | grep eth0 | grep ether | awk '{ print $17 }')
    - sed -i -e "s/MACADDRESS/$${mac}/g" /etc/netplan/60-eth0.yaml
    - netplan apply
    preKubeadmCommands:
    - bash -c /tmp/kubeadm-bootstrap.sh
    useExperimentalRetryJoin: true
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: AzureMachineTemplate
      name: ${CLUSTER_NAME}-control-plane
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  template:
    spec:
      dataDisks:
      - diskSizeGB: 256
        lun: 0
        nameSuffix: etcddisk
      image:
        marketplace:
          offer: capi
          publisher: cncf-upstream
          sku: k8s-1dot18dot8-ubuntu-1804
          version: 2020.08.17
      osDisk:
        diskSizeGB: 128
        osType: Linux
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      vmSize: ${AZURE_CONTROL_PLANE_MACHINE_TYPE}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: ${CLUSTER_NAME}-md-0
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${LINUX_WORKER_MACHINE_COUNT:-1}
  selector:
    matchLabels: null
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-md-0
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachineTemplate
        name: ${CLUSTER_NAME}-md-0
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-md-0
  namespace: default
spec:
  template:
    spec:
      image:
        marketplace:
          offer: capi
          publisher: cncf-upstream
          sku: k8s-1dot18dot8-ubuntu-1804
          version: 2020.08.17
      osDisk:
        diskSizeGB: 128
        managedDisk:
          storageAccountType: Premium_LRS
        osType: Linux
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      vmSize: ${AZURE_NODE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${CLUSTER_NAME}-md-0
  namespace: default
spec:
  template:
    spec:
      files:
      - contentFrom:
          secret:
            key: worker-node-azure.json
            name: ${CLUSTER_NAME}-md-0-azure-json
        owner: root:root
        path: /etc/kubernetes/azure.json
        permissions: "0644"
      - content: |
          network:
            version: 2
            ethernets:
              eth0:
                mtu: 1400
                match:
                  macaddress: MACADDRESS
                set-name: eth0
        owner: root:root
        path: /etc/netplan/60-eth0.yaml
        permissions: "0644"
      - content: |
          #!/bin/bash

          set -o nounset
          set -o pipefail
          set -o errexit
          [[ $(id -u) != 0 ]] && SUDO="sudo" || SUDO=""

          # This test installs release packages or binaries that are a result of the CI and release builds.
          # It runs '... --version' commands to verify that the binaries are correctly installed
          # and finally uninstalls the packages.
          # For the release packages it tests all versions in the support skew.
          LINE_SEPARATOR="*************************************************"
          echo "$$LINE_SEPARATOR"
          CI_VERSION=${CI_VERSION}
          if [[ "$${CI_VERSION}" != "" ]]; then
            CI_DIR=/tmp/k8s-ci
            mkdir -p $$CI_DIR
            declare -a PACKAGES_TO_TEST=("kubectl" "kubelet" "kubeadm")
            declare -a CONTAINERS_TO_TEST=("kube-apiserver" "kube-controller-manager" "kube-proxy" "kube-scheduler")
            CONTAINER_EXT="tar"
            echo "* testing CI version $$CI_VERSION"
            # Check for semver
            if [[ "$${CI_VERSION}" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              CI_URL="https://storage.googleapis.com/k8s-release-dev/ci/$${CI_VERSION}/bin/linux/amd64"
              VERSION_WITHOUT_PREFIX="${CI_VERSION#v}"
              DEBIAN_FRONTEND=noninteractive apt-get install -y apt-transport-https curl
              curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
              echo 'deb https://apt.kubernetes.io/ kubernetes-xenial main' > /etc/apt/sources.list.d/kubernetes.list
              apt-get update
              # replace . with \.
              VERSION_REGEX="${VERSION_WITHOUT_PREFIX//./\\.}"
              PACKAGE_VERSION="$(apt-cache madison kubelet|grep $${VERSION_REGEX}- | head -n1 | cut -d '|' -f 2 | tr -d '[:space:]')"
              for CI_PACKAGE in "$${PACKAGES_TO_TEST[@]}"; do
                echo "* installing package: $$CI_PACKAGE $${PACKAGE_VERSION}"
                DEBIAN_FRONTEND=noninteractive apt-get install -y $$CI_PACKAGE=$$PACKAGE_VERSION
              done
            else
                CI_URL="https://storage.googleapis.com/k8s-release-dev/ci/$${CI_VERSION}/bin/linux/amd64"
              fi
              for CI_PACKAGE in "$${PACKAGES_TO_TEST[@]}"; do
                echo "* downloading binary: $$CI_URL/$$CI_PACKAGE"
                wget "$$CI_URL/$$CI_PACKAGE" -O "$$CI_DIR/$$CI_PACKAGE"
                chmod +x "$$CI_DIR/$$CI_PACKAGE"
                mv "$$CI_DIR/$$CI_PACKAGE" "/usr/bin/$$CI_PACKAGE"
              done
              systemctl restart kubelet
            fi
            for CI_CONTAINER in "$${CONTAINERS_TO_TEST[@]}"; do
              echo "* downloading package: $$CI_URL/$$CI_CONTAINER.$$CONTAINER_EXT"
              wget "$$CI_URL/$$CI_CONTAINER.$$CONTAINER_EXT" -O "$$CI_DIR/$$CI_CONTAINER.$$CONTAINER_EXT"
              $${SUDO} ctr -n k8s.io images import "$$CI_DIR/$$CI_CONTAINER.$$CONTAINER_EXT" || echo "* ignoring expected 'ctr images import' result"
              $${SUDO} ctr -n k8s.io images tag k8s.gcr.io/$$CI_CONTAINER-amd64:"$${CI_VERSION//+/_}" k8s.gcr.io/$$CI_CONTAINER:"$${CI_VERSION//+/_}"
              $${SUDO} ctr -n k8s.io images tag k8s.gcr.io/$$CI_CONTAINER-amd64:"$${CI_VERSION//+/_}" gcr.io/k8s-staging-ci-images/$$CI_CONTAINER:"$${CI_VERSION//+/_}"
            done
          fi
          echo "* checking binary versions"
          echo "ctr version: " $(ctr version)
          echo "kubeadm version: " $(kubeadm version -o=short)
          echo "kubectl version: " $(kubectl version --client=true --short=true)
          echo "kubelet version: " $(kubelet --version)
          echo "$$LINE_SEPARATOR"
        owner: root:root
        path: /tmp/kubeadm-bootstrap.sh
        permissions: "0744"
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            azure-container-registry-config: /etc/kubernetes/azure.json
            cloud-config: /etc/kubernetes/azure.json
            cloud-provider: azure
          name: '{{ ds.meta_data["local_hostname"] }}'
      postKubeadmCommands:
      - mac=$(ip -o link | grep eth0 | grep ether | awk '{ print $17 }')
      - sed -i -e "s/MACADDRESS/$${mac}/g" /etc/netplan/60-eth0.yaml
      - netplan apply
      preKubeadmCommands:
      - bash -c /tmp/kubeadm-bootstrap.sh
      useExperimentalRetryJoin: true
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: ${CLUSTER_NAME}-md-win
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels: null
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-md-win
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachineTemplate
        name: ${CLUSTER_NAME}-md-win
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-md-win
  namespace: default
spec:
  template:
    spec:
      image:
        marketplace:
          offer: capi-windows
          publisher: cncf-upstream
          sku: k8s-1dot18dot19-windows-2019
          version: 2021.05.17
      osDisk:
        diskSizeGB: 128
        managedDisk:
          storageAccountType: Premium_LRS
        osType: Windows
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      vmSize: ${AZURE_NODE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${CLUSTER_NAME}-md-win
  namespace: default
spec:
  template:
    spec:
      files:
      - contentFrom:
          secret:
            key: worker-node-azure.json
            name: ${CLUSTER_NAME}-md-win-azure-json
        owner: root:root
        path: c:/k/azure.json
        permissions: "0644"
      - content: |
          # required as a work around for Flannel and Wins bugs
          # https://github.com/coreos/flannel/issues/1359
          # https://github.com/kubernetes-sigs/sig-windows-tools/issues/103#issuecomment-709426828
          ipmo C:\k\debug\hns.psm1;
          New-HnsNetwork -Type Overlay -AddressPrefix "192.168.255.0/30" -Gateway "192.168.255.1" -Name "External" -AdapterName "Ethernet 2" -SubnetPolicies @(@{Type = "VSID"; VSID = 9999; })
        path: C:/create-external-network.ps1
        permissions: "0744"
      - content: |
          # /tmp is assumed created and required for upstream e2e tests to pass
          New-Item -ItemType Directory -Force -Path C:\tmp\
        path: C:/create-temp-folder.ps1
        permissions: "0744"
      - content: |
          Stop-Service kubelet -Force

          $$CI_VERSION="${CI_VERSION}"
          if($$CI_VERSION -ne "")
          {
            $$binaries=@("kubeadm", "kubectl", "kubelet", "kube-proxy")
            $$ci_url="https://storage.googleapis.com/k8s-release-dev/ci/$$CI_VERSION/bin/windows/amd64"
            foreach ( $$binary in $$binaries )
            {
              echo "downloading binary: $$ci_url/$$binary.exe"
              curl.exe --retry 10 --retry-delay 5 "$$ci_url/$$binary.exe" --output "c:/k/$$binary.exe"
            }
          }

          # We are using a VHD that maps to v1.18.19 so the kubeproxy image is already pulled. (pull it just in case)
          # Tag it to the ci version.  The image knows how to use the copy locally.
          docker pull sigwindowstools/kube-proxy:v1.18.19-nanoserver
          docker tag sigwindowstools/kube-proxy:v1.18.19-nanoserver "sigwindowstools/kube-proxy:${CI_VERSION/+/_}-nanoserver"

          kubeadm.exe version -o=short
          kubectl.exe version --client=true --short=true
          kubelet.exe --version
        path: C:/replace-k8s-binaries.ps1
        permissions: "0744"
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            azure-container-registry-config: c:/k/azure.json
            cloud-config: c:/k/azure.json
            cloud-provider: azure
            pod-infra-container-image: mcr.microsoft.com/oss/kubernetes/pause:1.4.1
          name: '{{ ds.meta_data["local_hostname"] }}'
      postKubeadmCommands:
      - nssm set kubelet start SERVICE_AUTO_START
      preKubeadmCommands:
      - powershell c:/create-external-network.ps1
      - powershell C:/create-temp-folder.ps1
      - powershell C:/replace-k8s-binaries.ps1
      users:
      - groups: Administrators
        name: capi
        sshAuthorizedKeys:
        - ${AZURE_SSH_PUBLIC_KEY:=""}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureClusterIdentity
metadata:
  labels:
    clusterctl.cluster.x-k8s.io/move-hierarchy: "true"
  name: ${CLUSTER_IDENTITY_NAME}
  namespace: default
spec:
  allowedNamespaces: {}
  clientID: ${AZURE_CLIENT_ID}
  clientSecret:
    name: ${AZURE_CLUSTER_IDENTITY_SECRET_NAME}
    namespace: ${AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE}
  tenantID: ${AZURE_TENANT_ID}
  type: ServicePrincipal
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: ${CLUSTER_NAME}-flannel
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      cni: ${CLUSTER_NAME}-flannel
  resources:
  - kind: ConfigMap
    name: cni-${CLUSTER_NAME}-flannel
  strategy: ApplyOnce
---
apiVersion: v1
data:
  cni: |+
    ---
    apiVersion: policy/v1beta1
    kind: PodSecurityPolicy
    metadata:
      name: psp.flannel.unprivileged
      annotations:
        seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
        seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
        apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
        apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
    spec:
      privileged: false
      volumes:
        - configMap
        - secret
        - emptyDir
        - hostPath
      allowedHostPaths:
        - pathPrefix: "/etc/cni/net.d"
        - pathPrefix: "/etc/kube-flannel"
        - pathPrefix: "/run/flannel"
      readOnlyRootFilesystem: false
      # Users and groups
      runAsUser:
        rule: RunAsAny
      supplementalGroups:
        rule: RunAsAny
      fsGroup:
        rule: RunAsAny
      # Privilege Escalation
      allowPrivilegeEscalation: false
      defaultAllowPrivilegeEscalation: false
      # Capabilities
      allowedCapabilities: ['NET_ADMIN']
      defaultAddCapabilities: []
      requiredDropCapabilities: []
      # Host namespaces
      hostPID: false
      hostIPC: false
      hostNetwork: true
      hostPorts:
      - min: 0
        max: 65535
      # SELinux
      seLinux:
        # SELinux is unused in CaaSP
        rule: 'RunAsAny'
    ---
    kind: ClusterRole
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: flannel
    rules:
      - apiGroups: ['extensions']
        resources: ['podsecuritypolicies']
        verbs: ['use']
        resourceNames: ['psp.flannel.unprivileged']
      - apiGroups:
          - ""
        resources:
          - pods
        verbs:
          - get
      - apiGroups:
          - ""
        resources:
          - nodes
        verbs:
          - list
          - watch
      - apiGroups:
          - ""
        resources:
          - nodes/status
        verbs:
          - patch
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: flannel
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: flannel
    subjects:
    - kind: ServiceAccount
      name: flannel
      namespace: kube-system
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: flannel
      namespace: kube-system
    ---
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: kube-flannel-cfg
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    data:
      cni-conf.json: |
        {
          "name": "cbr0",
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "flannel",
              "delegate": {
                "hairpinMode": true,
                "isDefaultGateway": true
              }
            },
            {
              "type": "portmap",
              "capabilities": {
                "portMappings": true
              }
            }
          ]
        }
      net-conf.json: |
        {
          "Network": "10.244.0.0/16",
          "Backend": {
            "Type": "vxlan",
            "VNI" : 4096,
            "Port": 4789
          }
        }
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-amd64
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/os
                        operator: In
                        values:
                          - linux
                      - key: beta.kubernetes.io/arch
                        operator: In
                        values:
                          - amd64
          hostNetwork: true
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.12.0-amd64
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.12.0-amd64
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                add: ["NET_ADMIN"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
            - name: run
              hostPath:
                path: /run/flannel
            - name: cni
              hostPath:
                path: /etc/cni/net.d
            - name: flannel-cfg
              configMap:
                name: kube-flannel-cfg
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-arm64
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/os
                        operator: In
                        values:
                          - linux
                      - key: beta.kubernetes.io/arch
                        operator: In
                        values:
                          - arm64
          hostNetwork: true
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.12.0-arm64
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.12.0-arm64
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                 add: ["NET_ADMIN"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
            - name: run
              hostPath:
                path: /run/flannel
            - name: cni
              hostPath:
                path: /etc/cni/net.d
            - name: flannel-cfg
              configMap:
                name: kube-flannel-cfg
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-arm
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/os
                        operator: In
                        values:
                          - linux
                      - key: beta.kubernetes.io/arch
                        operator: In
                        values:
                          - arm
          hostNetwork: true
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.12.0-arm
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.12.0-arm
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                 add: ["NET_ADMIN"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
            - name: run
              hostPath:
                path: /run/flannel
            - name: cni
              hostPath:
                path: /etc/cni/net.d
            - name: flannel-cfg
              configMap:
                name: kube-flannel-cfg
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-ppc64le
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/os
                        operator: In
                        values:
                          - linux
                      - key: beta.kubernetes.io/arch
                        operator: In
                        values:
                          - ppc64le
          hostNetwork: true
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.12.0-ppc64le
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.12.0-ppc64le
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                 add: ["NET_ADMIN"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
            - name: run
              hostPath:
                path: /run/flannel
            - name: cni
              hostPath:
                path: /etc/cni/net.d
            - name: flannel-cfg
              configMap:
                name: kube-flannel-cfg
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-s390x
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/os
                        operator: In
                        values:
                          - linux
                      - key: beta.kubernetes.io/arch
                        operator: In
                        values:
                          - s390x
          hostNetwork: true
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.12.0-s390x
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.12.0-s390x
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                 add: ["NET_ADMIN"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
            - name: run
              hostPath:
                path: /run/flannel
            - name: cni
              hostPath:
                path: /etc/cni/net.d
            - name: flannel-cfg
              configMap:
                name: kube-flannel-cfg
    ---
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: kube-flannel-windows-cfg
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    data:
      run.ps1: |
        $ErrorActionPreference = "Stop";

        mkdir -force /host/etc/cni/net.d
        mkdir -force /host/etc/kube-flannel
        mkdir -force /host/opt/cni/bin
        mkdir -force /host/k/flannel
        mkdir -force /host/k/flannel/var/run/secrets/kubernetes.io/serviceaccount

        $cniJson = get-content /etc/kube-flannel-windows/cni-conf.json | ConvertFrom-Json
        $serviceSubnet = yq r /etc/kubeadm-config/ClusterConfiguration networking.serviceSubnet
        $podSubnet = yq r /etc/kubeadm-config/ClusterConfiguration networking.podSubnet
        $networkJson = wins cli net get | convertfrom-json

        $cniJson.delegate.policies[0].Value.ExceptionList = $serviceSubnet, $podSubnet
        $cniJson.delegate.policies[1].Value.DestinationPrefix = $serviceSubnet
        Set-Content -Path /host/etc/cni/net.d/10-flannel.conf ($cniJson | ConvertTo-Json -depth 100)

        cp -force /etc/kube-flannel/net-conf.json /host/etc/kube-flannel
        cp -force -recurse /cni/* /host/opt/cni/bin
        cp -force /k/flannel/* /host/k/flannel/
        cp -force /kube-proxy/kubeconfig.conf /host/k/flannel/kubeconfig.yml
        cp -force /var/run/secrets/kubernetes.io/serviceaccount/* /host/k/flannel/var/run/secrets/kubernetes.io/serviceaccount/
        wins cli process run --path /k/flannel/setup.exe --args "--mode=overlay --interface=Ethernet 2"
        wins cli route add --addresses 169.254.169.254
        wins cli process run --path /k/flannel/flanneld.exe --args "--kube-subnet-mgr --kubeconfig-file /k/flannel/kubeconfig.yml" --envs "POD_NAME=$env:POD_NAME POD_NAMESPACE=$env:POD_NAMESPACE"
      cni-conf.json: |
        {
          "name": "flannel.4096",
          "cniVersion": "0.3.0",
          "type": "flannel",
          "capabilities": {
            "dns": true
          },
          "delegate": {
            "type": "win-overlay",
            "policies": [
              {
                "Name": "EndpointPolicy",
                "Value": {
                  "Type": "OutBoundNAT",
                  "ExceptionList": []
                }
              },
              {
                "Name": "EndpointPolicy",
                "Value": {
                  "Type": "ROUTE",
                  "DestinationPrefix": "",
                  "NeedEncap": true
                }
              }
            ]
          }
        }
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds-windows-amd64
      labels:
        tier: node
        app: flannel
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: kubernetes.io/os
                        operator: In
                        values:
                          - windows
                      - key: kubernetes.io/arch
                        operator: In
                        values:
                          - amd64
          hostNetwork: true
          serviceAccountName: flannel
          tolerations:
          - operator: Exists
            effect: NoSchedule
          containers:
          - name: kube-flannel
            image: sigwindowstools/flannel:v0.13.0-nanoserver
            command:
            - pwsh
            args:
            - -file
            - /etc/kube-flannel-windows/run.ps1
            volumeMounts:
            - name: wins
              mountPath: \\.\pipe\rancher_wins
            - name: host
              mountPath: /host
            - name: kube-proxy
              mountPath: /kube-proxy
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
            - name: flannel-windows-cfg
              mountPath: /etc/kube-flannel-windows/
            - name: kubeadm-config
              mountPath: /etc/kubeadm-config/
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
          volumes:
          - name: wins
            hostPath:
              path: \\.\pipe\rancher_wins
              type: null
          - name: opt
            hostPath:
              path: /opt
          - name: host
            hostPath:
              path: /
          - name: cni
            hostPath:
              path: /etc
          - name: flannel-cfg
            configMap:
              name: kube-flannel-cfg
          - name: flannel-windows-cfg
            configMap:
              name: kube-flannel-windows-cfg
          - name: kube-proxy
            configMap:
              name: kube-proxy
          - name: kubeadm-config
            configMap:
              name: kubeadm-config

  proxy: |
    apiVersion: v1
    data:
      run-script.ps1: |-
        $ErrorActionPreference = "Stop";
        mkdir -force /host/var/lib/kube-proxy/var/run/secrets/kubernetes.io/serviceaccount
        mkdir -force /host/k/kube-proxy

        $$CI_VERSION="${CI_VERSION:-}"
        if($$CI_VERSION -ne "" -And (Test-Path -Path "/host/k/kube-proxy.exe"))
        {
          cp -force /host/k/kube-proxy.exe /k/kube-proxy/kube-proxy.exe
        }

        cp -force /k/kube-proxy/* /host/k/kube-proxy
        cp -force /var/lib/kube-proxy/* /host/var/lib/kube-proxy
        cp -force /var/run/secrets/kubernetes.io/serviceaccount/* /host/var/lib/kube-proxy/var/run/secrets/kubernetes.io/serviceaccount #FIXME?

        $networkName = (Get-Content /host/etc/cni/net.d/* | ConvertFrom-Json).name
        $sourceVip = ($env:POD_IP -split "\.")[0..2] + 0 -join "."
        yq w -i /host/var/lib/kube-proxy/config.conf winkernel.sourceVip $sourceVip
        yq w -i /host/var/lib/kube-proxy/config.conf winkernel.networkName $networkName
        yq w -i /host/var/lib/kube-proxy/config.conf featureGates.WinOverlay true
        yq w -i /host/var/lib/kube-proxy/config.conf mode "kernelspace"
        wins cli process run --path /k/kube-proxy/kube-proxy.exe --args "--v=6 --config=/var/lib/kube-proxy/config.conf --hostname-override=$env:NODE_NAME --feature-gates=WinOverlay=true"
    kind: ConfigMap
    metadata:
      labels:
        app: kube-proxy
      name: kube-proxy-windows
      namespace: kube-system
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      labels:
        k8s-app: kube-proxy
      name: kube-proxy-windows
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          k8s-app: kube-proxy-windows
      template:
        metadata:
          labels:
            k8s-app: kube-proxy-windows
        spec:
          serviceAccountName: kube-proxy
          containers:
          - command:
            - pwsh
            args:
            - -file
            - /var/lib/kube-proxy-windows/run-script.ps1
            env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            image: sigwindowstools/kube-proxy:${KUBERNETES_VERSION/+/_}-nanoserver
            name: kube-proxy
            volumeMounts:
            - name: wins
              mountPath: \\.\pipe\rancher_wins
            - name: host
              mountPath: /host
            - mountPath: /var/lib/kube-proxy
              name: kube-proxy
            - mountPath: /var/lib/kube-proxy-windows
              name: kube-proxy-windows
          nodeSelector:
            kubernetes.io/os: windows
          tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
          - operator: Exists
          volumes:
          - name: wins
            hostPath:
              path: \\.\pipe\rancher_wins
              type: null
          - configMap:
              defaultMode: 420
              name: kube-proxy-windows
            name: kube-proxy-windows
          - configMap:
              name: kube-proxy
            name: kube-proxy
          - hostPath:
              path: /
            name: host
      updateStrategy:
        type: RollingUpdate
kind: ConfigMap
metadata:
  annotations:
    note: generated
  labels:
    type: generated
  name: cni-${CLUSTER_NAME}-flannel
  namespace: default
