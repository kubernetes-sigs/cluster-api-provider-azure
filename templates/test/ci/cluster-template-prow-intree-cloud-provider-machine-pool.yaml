apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    cni: calico
    cni-windows: ${CLUSTER_NAME}-calico
    containerd-logger: enabled
    csi-proxy: enabled
    windows: enabled
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 192.168.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureCluster
    name: ${CLUSTER_NAME}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: default
spec:
  additionalTags:
    buildProvenance: ${BUILD_PROVENANCE}
    creationTimestamp: ${TIMESTAMP}
    jobName: ${JOB_NAME}
  identityRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AzureClusterIdentity
    name: ${CLUSTER_IDENTITY_NAME}
  location: ${AZURE_LOCATION}
  networkSpec:
    subnets:
    - name: control-plane-subnet
      role: control-plane
    - name: node-subnet
      role: node
    vnet:
      name: ${AZURE_VNET_NAME:=${CLUSTER_NAME}-vnet}
  resourceGroup: ${AZURE_RESOURCE_GROUP:=${CLUSTER_NAME}}
  subscriptionID: ${AZURE_SUBSCRIPTION_ID}
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        extraArgs:
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        extraVolumes:
        - hostPath: /etc/kubernetes/azure.json
          mountPath: /etc/kubernetes/azure.json
          name: cloud-config
          readOnly: true
        timeoutForControlPlane: 20m
      controllerManager:
        extraArgs:
          allocate-node-cidrs: "false"
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
          cluster-name: ${CLUSTER_NAME}
          v: "4"
        extraVolumes:
        - hostPath: /etc/kubernetes/azure.json
          mountPath: /etc/kubernetes/azure.json
          name: cloud-config
          readOnly: true
      etcd:
        local:
          dataDir: /var/lib/etcddisk/etcd
          extraArgs:
            quota-backend-bytes: "8589934592"
    diskSetup:
      filesystems:
      - device: /dev/disk/azure/scsi1/lun0
        extraOpts:
        - -E
        - lazy_itable_init=1,lazy_journal_init=1
        filesystem: ext4
        label: etcd_disk
      - device: ephemeral0.1
        filesystem: ext4
        label: ephemeral0
        replaceFS: ntfs
      partitions:
      - device: /dev/disk/azure/scsi1/lun0
        layout: true
        overwrite: false
        tableType: gpt
    files:
    - contentFrom:
        secret:
          key: control-plane-azure.json
          name: ${CLUSTER_NAME}-control-plane-azure-json
      owner: root:root
      path: /etc/kubernetes/azure.json
      permissions: "0644"
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          azure-container-registry-config: /etc/kubernetes/azure.json
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        name: '{{ ds.meta_data["local_hostname"] }}'
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          azure-container-registry-config: /etc/kubernetes/azure.json
          cloud-config: /etc/kubernetes/azure.json
          cloud-provider: azure
        name: '{{ ds.meta_data["local_hostname"] }}'
    mounts:
    - - LABEL=etcd_disk
      - /var/lib/etcddisk
    postKubeadmCommands: []
    preKubeadmCommands: []
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: AzureMachineTemplate
      name: ${CLUSTER_NAME}-control-plane
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-control-plane
  namespace: default
spec:
  template:
    spec:
      dataDisks:
      - diskSizeGB: 256
        lun: 0
        nameSuffix: etcddisk
      osDisk:
        diskSizeGB: 128
        osType: Linux
      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
      vmSize: ${AZURE_CONTROL_PLANE_MACHINE_TYPE}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachinePool
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_MACHINE_COUNT}
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfig
          name: ${CLUSTER_NAME}-mp-0
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachinePool
        name: ${CLUSTER_NAME}-mp-0
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachinePool
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  location: ${AZURE_LOCATION}
  strategy:
    rollingUpdate:
      deletePolicy: Oldest
      maxSurge: 25%
      maxUnavailable: 1
    type: RollingUpdate
  template:
    osDisk:
      diskSizeGB: 30
      managedDisk:
        storageAccountType: Premium_LRS
      osType: Linux
    sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
    vmExtensions:
    - name: CustomScript
      protectedSettings:
        commandToExecute: |
          #!/bin/sh
          echo "This script is a no-op used for extension testing purposes ..."
          touch test_file
      publisher: Microsoft.Azure.Extensions
      version: "2.1"
    vmSize: ${AZURE_NODE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfig
metadata:
  name: ${CLUSTER_NAME}-mp-0
  namespace: default
spec:
  files:
  - contentFrom:
      secret:
        key: worker-node-azure.json
        name: ${CLUSTER_NAME}-mp-0-azure-json
    owner: root:root
    path: /etc/kubernetes/azure.json
    permissions: "0644"
  joinConfiguration:
    nodeRegistration:
      kubeletExtraArgs:
        azure-container-registry-config: /etc/kubernetes/azure.json
        cloud-config: /etc/kubernetes/azure.json
        cloud-provider: azure
      name: '{{ ds.meta_data["local_hostname"] }}'
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureClusterIdentity
metadata:
  labels:
    clusterctl.cluster.x-k8s.io/move-hierarchy: "true"
  name: ${CLUSTER_IDENTITY_NAME}
  namespace: default
spec:
  allowedNamespaces: {}
  clientID: ${AZURE_CLIENT_ID}
  clientSecret:
    name: ${AZURE_CLUSTER_IDENTITY_SECRET_NAME}
    namespace: ${AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE}
  tenantID: ${AZURE_TENANT_ID}
  type: ServicePrincipal
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachinePool
metadata:
  name: ${CLUSTER_NAME}-mp-win
  namespace: default
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WINDOWS_WORKER_MACHINE_COUNT:-0}
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfig
          name: ${CLUSTER_NAME}-mp-win
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AzureMachinePool
        name: ${CLUSTER_NAME}-mp-win
      version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: AzureMachinePool
metadata:
  annotations:
    runtime: containerd
    windowsServerVersion: ${WINDOWS_SERVER_VERSION:=""}
  name: ${CLUSTER_NAME}-mp-win
  namespace: default
spec:
  location: ${AZURE_LOCATION}
  template:
    osDisk:
      diskSizeGB: 128
      managedDisk:
        storageAccountType: Premium_LRS
      osType: Windows
    sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=""}
    vmSize: ${AZURE_NODE_MACHINE_TYPE}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfig
metadata:
  name: ${CLUSTER_NAME}-mp-win
  namespace: default
spec:
  files:
  - contentFrom:
      secret:
        key: worker-node-azure.json
        name: ${CLUSTER_NAME}-mp-win-azure-json
    owner: root:root
    path: c:/k/azure.json
    permissions: "0644"
  - content: Add-MpPreference -ExclusionProcess C:/opt/cni/bin/calico.exe
    path: C:/defender-exclude-calico.ps1
    permissions: "0744"
  joinConfiguration:
    nodeRegistration:
      criSocket: npipe:////./pipe/containerd-containerd
      kubeletExtraArgs:
        azure-container-registry-config: c:/k/azure.json
        cloud-config: c:/k/azure.json
        cloud-provider: azure
        pod-infra-container-image: mcr.microsoft.com/oss/kubernetes/pause:3.4.1
      name: '{{ ds.meta_data["local_hostname"] }}'
  postKubeadmCommands:
  - nssm set kubelet start SERVICE_AUTO_START
  - powershell C:/defender-exclude-calico.ps1
  preKubeadmCommands:
  - powershell c:/create-external-network.ps1
  users:
  - groups: Administrators
    name: capi
    sshAuthorizedKeys:
    - ${AZURE_SSH_PUBLIC_KEY:=""}
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: ${CLUSTER_NAME}-calico-windows
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      cni-windows: ${CLUSTER_NAME}-calico
  resources:
  - kind: ConfigMap
    name: cni-${CLUSTER_NAME}-calico-windows
  strategy: ApplyOnce
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: csi-proxy
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      csi-proxy: enabled
  resources:
  - kind: ConfigMap
    name: csi-proxy-addon
  strategy: ApplyOnce
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: containerd-logger-${CLUSTER_NAME}
  namespace: default
spec:
  clusterSelector:
    matchLabels:
      containerd-logger: enabled
  resources:
  - kind: ConfigMap
    name: containerd-logger-${CLUSTER_NAME}
  strategy: ApplyOnce
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: calico
  namespace: default
spec:
  chartName: tigera-operator
  clusterSelector:
    matchLabels:
      cni: calico
  namespace: tigera-operator
  releaseName: projectcalico
  repoURL: https://docs.tigera.io/calico/charts
  valuesTemplate: |-
    installation:
      cni:
        type: Calico
        ipam:
          strictAffinity: true
          type: Calico
      calicoNetwork:
        bgp: Disabled
        windowsDataplane: HNS
        mtu: 1350
        ipPools:
        ipPools:{{range $i, $cidr := .Cluster.spec.clusterNetwork.pods.cidrBlocks }}
        - cidr: {{ $cidr }}
          encapsulation: VXLAN{{end}}
      serviceCIDRs: {{range $i, $cidr := .Cluster.spec.clusterNetwork.services.cidrBlocks }}
        - {{ $cidr }}{{end}}
      registry: docker.io/
    # Image and registry configuration for the tigera/operator pod.
    tigeraOperator:
      image: tigera-operator
      registry: jsturtevant
      version: latest
    calicoctl:
      image: mcr.microsoft.com/oss/calico/ctl
  version: ${CALICO_VERSION}
---
apiVersion: addons.cluster.x-k8s.io/v1alpha1
kind: HelmChartProxy
metadata:
  name: azuredisk-csi-driver-chart
  namespace: default
spec:
  chartName: azuredisk-csi-driver
  clusterSelector:
    matchLabels:
      azuredisk-csi: "true"
  namespace: kube-system
  releaseName: azuredisk-csi-driver-oot
  repoURL: https://raw.githubusercontent.com/kubernetes-sigs/azuredisk-csi-driver/master/charts
  valuesTemplate: |-
    controller:
      replicas: 1
      runOnControlPlane: true
    windows:
      useHostProcessContainers: {{ hasKey .Cluster.metadata.labels "cni-windows" }}
---
apiVersion: v1
data:
  proxy: |
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      labels:
        k8s-app: kube-proxy
      name: kube-proxy-windows
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          k8s-app: kube-proxy-windows
      template:
        metadata:
          labels:
            k8s-app: kube-proxy-windows
        spec:
          serviceAccountName: kube-proxy
          securityContext:
            windowsOptions:
              hostProcess: true
              runAsUserName: "NT AUTHORITY\\system"
          hostNetwork: true
          containers:
          - image: sigwindowstools/kube-proxy:${KUBERNETES_VERSION/+/_}-calico-hostprocess
            args: ["$env:CONTAINER_SANDBOX_MOUNT_POINT/kube-proxy/start.ps1"]
            workingDir: "$env:CONTAINER_SANDBOX_MOUNT_POINT/kube-proxy/"
            name: kube-proxy
            env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBEPROXY_PATH
              valueFrom:
                configMapKeyRef:
                  name: windows-kubeproxy-ci
                  key: KUBEPROXY_PATH
                  optional: true
            volumeMounts:
            - mountPath: /var/lib/kube-proxy
              name: kube-proxy
          nodeSelector:
            kubernetes.io/os: windows
          tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
          - operator: Exists
          volumes:
          - configMap:
              name: kube-proxy
            name: kube-proxy
      updateStrategy:
        type: RollingUpdate
kind: ConfigMap
metadata:
  annotations:
    note: generated
  labels:
    type: generated
  name: cni-${CLUSTER_NAME}-calico-windows
  namespace: default
---
apiVersion: v1
data:
  csi-proxy: |
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      labels:
        k8s-app: csi-proxy
      name: csi-proxy
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          k8s-app: csi-proxy
      template:
        metadata:
          labels:
            k8s-app: csi-proxy
        spec:
          nodeSelector:
            "kubernetes.io/os": windows
          securityContext:
            windowsOptions:
              hostProcess: true
              runAsUserName: "NT AUTHORITY\\SYSTEM"
          hostNetwork: true
          containers:
            - name: csi-proxy
              image: ghcr.io/kubernetes-sigs/sig-windows/csi-proxy:v1.0.2
kind: ConfigMap
metadata:
  annotations:
    note: generated
  labels:
    type: generated
  name: csi-proxy-addon
  namespace: default
---
apiVersion: v1
data:
  containerd-windows-logger: |
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      labels:
        k8s-app: containerd-logger
      name: containerd-logger
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          k8s-app: containerd-logger
      template:
        metadata:
          labels:
            k8s-app: containerd-logger
        spec:
          securityContext:
            windowsOptions:
              hostProcess: true
              runAsUserName: "NT AUTHORITY\\system"
          hostNetwork: true
          containers:
          - image: ghcr.io/kubernetes-sigs/sig-windows/eventflow-logger:v0.1.0
            args: [ "config.json" ]
            name: containerd-logger
            imagePullPolicy: Always
            volumeMounts:
            - name: containerd-logger-config
              mountPath: /config.json
              subPath: config.json
          nodeSelector:
            kubernetes.io/os: windows
          tolerations:
          - key: CriticalAddonsOnly
            operator: Exists
          - operator: Exists
          volumes:
          - configMap:
              name: containerd-logger-config
            name: containerd-logger-config
      updateStrategy:
        type: RollingUpdate
    ---
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: containerd-logger-config
      namespace: kube-system
    data:
      config.json: |
        {
          "inputs": [
            {
              "type": "ETW",
              "sessionNamePrefix": "containerd",
              "cleanupOldSessions": true,
              "reuseExistingSession": true,
              "providers": [
                {
                  "providerName": "Microsoft.Virtualization.RunHCS",
                  "providerGuid": "0B52781F-B24D-5685-DDF6-69830ED40EC3",
                  "level": "Verbose"
                },
                {
                  "providerName": "ContainerD",
                  "providerGuid": "2acb92c0-eb9b-571a-69cf-8f3410f383ad",
                  "level": "Verbose"
                }
              ]
            }
          ],
          "filters": [
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == Stats && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == hcsshim::LayerID && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == hcsshim::NameToGuid && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == containerd.task.v2.Task.Stats && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == containerd.task.v2.Task.State && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == HcsGetProcessProperties && hasnoproperty error"
            },
            {
                "type": "drop",
                "include": "ProviderName == Microsoft.Virtualization.RunHCS && name == HcsGetComputeSystemProperties && hasnoproperty error"
            }
          ],
          "outputs": [
            {
              "type": "StdOutput"
            }
          ],
          "schemaVersion": "2016-08-11"
        }
kind: ConfigMap
metadata:
  annotations:
    note: generated
  labels:
    type: generated
  name: containerd-logger-${CLUSTER_NAME}
  namespace: default
